#######################################################################################################################
# Functions to load the data of the homogeneous_reactor model
#######################################################################################################################

# import packages #####################################################################################################
import numpy as np
import pandas as pd
import cantera as ct
import torch
from torch.utils import data
from pathlib import Path
from sklearn import preprocessing


def load_samples(mechanism_input, nbr_run, feature_select, features, labels, select_data, category):
    """
    Function to load the samples generated by the homogeneous reactor, select certain parts of the samples and split
    them in input and target data

    :parameter
    :param mechanism_input:     - str -             Name of mechanism used in the homogeneous reactor
    :param nbr_run:             - int -             Number to identify the run of the reactor data
    :param feature_select:      - dict -            features values which should be included or excluded in training
    :param features:            - list of str -     features
    :param labels:              - list of str -     labels
    :param select_data:         - str -             if 'exclude' feature_select data is excluded, if 'include' only
                                                    feature_select data is included
    :param category:            - str -             category of the samples (train, test, exp)

    :returns:
    :return x_samples:          - pd dataframe -    samples
    :return y_samples:          - pd dataframe -    targets
    """

    # create Path to samples and load data as dataframe
    mechanism = chose_mechanism(mechanism_input)
    path = Path(__file__).parents[3] / '000-homogeneous_reactor/data/00002-reactor-OME/{}/{}_{}_samples.csv'.\
        format(mechanism, nbr_run, category)
#    path = '/media/pascal/TOSHIBA EXT/BA/{}_{}_samples.csv'.format(nbr_run, category)
    data = pd.read_csv(path)

    # exclude or only include certain data
    data = select_samples(data, feature_select, select_data)

    # split the data in samples and targets
    x_samples = data[features]
    y_samples = data[labels]

    return x_samples, y_samples


# function to normalize the data ######################################################################################
def normalize_df(df, scaler):
    """
    Function to normalize dataframes

    :parameter:
    :param df:      - pd dataframe -    Dataframe which should be normalized
    :param scaler:                      MinMaxScaler of the dataframe

    :returns:
    :return df:     - pd dataframe -    normalized dataframe
    :return scaler:                     MinMaxScaler of the dataframe
    """

    columns = df.columns
    x = df.values  # returns a numpy array
    if scaler is None:
        min_max_scaler = preprocessing.MinMaxScaler()
        scaler = min_max_scaler.fit(x)
    x_scaled = scaler.transform(x)
    df = pd.DataFrame(x_scaled)
    df.columns = columns
    return df, scaler


# function to denormalize the data ####################################################################################
def denormalize_df(df, scaler):
    """
    Function to denormalize dataframes; inverse function to normalize dataframe

    :parameter:
    :param df:      - pd dataframe -    Dataframe which should be denormalized
    :param scaler:                      MinMaxScaler of the dataframe

    :returns:
    :return df:     - pd dataframe -    normalized dataframe
    """

    columns = df.columns
    x = df.values  # returns a numpy array
    x_scaled = scaler.inverse_transform(x)
    df = pd.DataFrame(x_scaled)
    df.columns = columns
    return df


# function to include certain data if demanded ########################################################################
def select_samples(df, feature_select, select_data):
    """
    Function to select data with certain feature values and then exclude it from the data or reduce the data to only the
    corresponding samples

    :parameter
    :param df:              - pd dataframe -    Dataframe of samples, targets
    :param feature_select:  - dict -            features values which should be included or excluded in training
    :param select_data:     - bool -            if 'exclude' feature_select data is excluded, if 'include' only
                                                feature_select data is included

    :returns:
    :return df:             - pd dataframe -    reduced dataframe
    """

    for feature, value in feature_select.items():
        if feature == 'P_0':
            value = np.array(value) * ct.one_atm
        elif feature == 'phi':
            df['phi'] = df['phi'].round(2)
            if select_data == 'include':
                value = [value]

        if value is not None and select_data == 'include':

            # rename the column in df to feature in order to call it later
            df = df.rename(columns={'{}'.format(feature): 'feature'})

            for i, value_run in enumerate(value):
                df = df[df.feature == value_run]

            # rename the column back to its original name
            df = df.rename(columns={'feature': '{}'.format(feature)})

        elif value is not None and select_data == 'exclude':

            # rename the column in df to feature in order to call it later
            df = df.rename(columns={'{}'.format(feature): 'feature'})

            for i, value_run in enumerate(value):
                df = df[df.feature != value_run]

            # rename the column back to its original name
            df = df.rename(columns={'feature': '{}'.format(feature)})

    return df


# function to assign official mechanism name ##########################################################################
def chose_mechanism(mechanism_input):
    """
    Function to chose the official name of the entered mechanism

    :parameter
    :param mechanism_input:     - str -     Entered mechanism name

    :returns:
    :return mechanism:          - str -     Official mechanism name
    """

    if mechanism_input == 'he':
        mechanism = 'he_2018.xml'
    elif mechanism_input == 'cai':
        mechanism = 'cai_ome14_2019.xml'
    elif mechanism_input == 'sun':
        mechanism = 'sun_2017.xml'

    return mechanism


# function called by MLP script #######################################################################################
def load_dataloader(x_samples, y_samples, batch_fraction, x_scaler, y_scaler):
    """
    Function to normalize, split into training and validation and combine samples and targets in dataloader

    :parameter:
    :param x_samples:       - pd dataframe -    samples
    :param y_samples:       - pd dataframe -    targets
    :param batch_fraction:  - int -             batch_size is defined as len(samples)/batch_fraction
    :param x_scaler:                            MinMaxScaler of samples
    :param y_scaler:                            MinMaxScaler of targets

    :returns:
    :return loader:         - dataloader -      pytorch dataloader, combination of training samples and targets
    """

    # Normalize samples and targets
    x_samples, _ = normalize_df(x_samples, scaler=x_scaler)

    y_samples, _ = normalize_df(y_samples, y_scaler)

    # transform to torch tensor
    x_samples = torch.tensor(x_samples.values).float()
    y_samples = torch.tensor(y_samples.values).float()
    tensor = data.TensorDataset(x_samples, y_samples)

    # prepare data loaders
    batch_size = int(len(tensor) / batch_fraction)
    num_workers = 8

    loader = torch.utils.data.DataLoader(tensor, batch_size=batch_size, num_workers=num_workers)

    return loader